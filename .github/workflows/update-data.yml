name: Update Field Reports Data

on:
  # Run every day at 1 PM UTC
  schedule:
    - cron: '0 13 * * *'
  
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:
  
  # Optional: Run on push to specific files (for testing)
  push:
    branches:
      - master
    paths:
      - 'fetch_reports.py'
      - 'aggregate_reports.py'

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Use default token for pushing and give full history so we can rebase safely
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          persist-credentials: true
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          #cache: 'pip'
          
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas
          
      - name: Fetch field reports from IFRC GO API
        run: |
          echo "üì• Fetching latest field reports..."
          python fetch_reports.py
          
      - name: Aggregate data for visualization
        run: |
          echo "üìä Aggregating data by month and disaster type..."
          python aggregate_reports.py
          
      - name: Check if data has changed
        id: check-changes
        run: |
          if git diff --quiet field_reports.json field_reports_aggregated.json field_reports.csv; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è No changes detected in data files"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Data has been updated"
          fi
          
      - name: Commit and push updated data
        if: steps.check-changes.outputs.changed == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --local user.name 'github-actions[bot]'
          git config --local user.email 'github-actions[bot]@users.noreply.github.com'
          git add field_reports.json field_reports_aggregated.json field_reports.csv

          # Only commit when there are staged changes
          if git diff --staged --quiet; then
            echo "No staged changes to commit"
            exit 0
          fi

          TOTAL_REPORTS=$(python -c "import json,sys; print(len(json.load(open('field_reports.json'))))")
          COMMIT_MSG="chore: Update field reports data [automated] - Updated: $(date -u +'%Y-%m-%d %H:%M:%S UTC') - Total reports: ${TOTAL_REPORTS}"
          git commit -m "${COMMIT_MSG}"

          # Fetch remote and rebase to avoid non-fast-forward push failures
          git fetch origin master
          git checkout master
          set +e
          git rebase origin/master
          REBASE_STATUS=$?
          set -e
          if [ $REBASE_STATUS -ne 0 ]; then
            echo "Rebase failed, attempting to abort and pull --rebase"
            git rebase --abort || true
            git pull --rebase origin master
          fi

          # Push changes; if remote has new commits, the previous rebase should have handled it
          git push origin master
          
      - name: Deployment info
        if: steps.check-changes.outputs.changed == 'true'
        run: |
          echo "üöÄ Data updated successfully!"
          echo "üìç Vercel will automatically redeploy with the new data"
          echo "üîó Check your Vercel dashboard for deployment status"
          
      - name: No changes info
        if: steps.check-changes.outputs.changed == 'false'
        run: |
          echo "‚ÑπÔ∏è No new data to update"
          echo "üìÖ Last run: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
