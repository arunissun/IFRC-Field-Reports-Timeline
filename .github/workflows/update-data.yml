name: Update Field Reports Data

on:
  # Run every day at 1 PM UTC
  schedule:
    - cron: '0 13 * * *'
  
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:
  
  # Optional: Run on push to specific files (for testing)
  push:
    branches:
      - master
    paths:
      - 'fetch_reports.py'
      - 'aggregate_reports.py'

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Checkout the master branch directly and fetch full history
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: 'refs/heads/master'
          fetch-depth: 0
          persist-credentials: true
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          #cache: 'pip'
          
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas
          
      - name: Fetch field reports from IFRC GO API
        run: |
          echo "ğŸ“¥ Fetching latest field reports..."
          python fetch_reports.py
          
      - name: Aggregate data for visualization
        run: |
          echo "ğŸ“Š Aggregating data by month and disaster type..."
          python aggregate_reports.py
          
      - name: Check if data has changed
        id: check-changes
        run: |
          if git diff --quiet field_reports.json field_reports_aggregated.json field_reports.csv; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸ No changes detected in data files"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "âœ… Data has been updated"
          fi
          
      - name: Commit and push updated data
        if: steps.check-changes.outputs.changed == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --local user.name 'github-actions[bot]'
          git config --local user.email 'github-actions[bot]@users.noreply.github.com'
          git add field_reports.json field_reports_aggregated.json field_reports.csv

          # Only commit when there are staged changes
          if git diff --staged --quiet; then
            echo "No staged changes to commit"
            exit 0
          fi

          # Fetch latest changes from remote
          echo "ğŸ”„ Fetching latest changes from origin/master"
          git fetch origin master

          # Create commit with new data
          TOTAL_REPORTS=$(python -c "import json,sys; print(len(json.load(open('field_reports.json'))))")
          COMMIT_MSG="chore: Update field reports data [automated] - Updated: $(date -u +'%Y-%m-%d %H:%M:%S UTC') - Total reports: ${TOTAL_REPORTS}"
          git commit -m "${COMMIT_MSG}"

          # Rebase onto latest remote to integrate any remote changes
          echo "ğŸ”„ Rebasing onto origin/master"
          git rebase origin/master

          # Push changes
          echo "ğŸ“¤ Pushing changes to origin/master"
          git push origin HEAD:master || {
            echo "âš ï¸ Push failed, attempting force-with-lease"
            git push --force-with-lease origin HEAD:master
          }
          
      - name: Deployment info
        if: steps.check-changes.outputs.changed == 'true'
        run: |
          echo "ğŸš€ Data updated successfully!"
          echo "ğŸ“ Vercel will automatically redeploy with the new data"
          echo "ğŸ”— Check your Vercel dashboard for deployment status"
          
      - name: No changes info
        if: steps.check-changes.outputs.changed == 'false'
        run: |
          echo "â„¹ï¸ No new data to update"
          echo "ğŸ“… Last run: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
